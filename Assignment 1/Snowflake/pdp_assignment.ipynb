{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76004, 21)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'Downloads/New folder/CATALOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['time_utc'].str.contains(\"2019\")]\n",
    "catalogidlist = []\n",
    "for ind in df1.index: \n",
    "     catalogidlist.append(df1['event_id'][ind])\n",
    "        \n",
    "cleanedList = [event_id for event_id in catalogidlist if str(event_id) != 'nan']\n",
    "cleanedList = [round(event_id) for event_id in cleanedList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdetails = pd.read_csv(r'Downloads/New folder/StormEvents_details-ftp_v1.0_d2019_c20210223.csv')\n",
    "dfdetails = dfdetails[dfdetails['EVENT_ID'].isin(cleanedList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffatalities = pd.read_csv(r'Downloads/New folder/StormEvents_fatalities-ftp_v1.0_d2019_c20210223.csv')\n",
    "dffatalities = dffatalities[dffatalities['EVENT_ID'].isin(cleanedList)]\n",
    "\n",
    "dflocations = pd.read_csv(r'Downloads/New folder/StormEvents_locations-ftp_v1.0_d2019_c20210223.csv')\n",
    "dflocations = dflocations[dflocations['EVENT_ID'].isin(cleanedList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_index</th>\n",
       "      <th>img_type</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>minute_offsets</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>llcrnrlat</th>\n",
       "      <th>...</th>\n",
       "      <th>EPISODE_ID_y</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>LOCATION_INDEX</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LAT2</th>\n",
       "      <th>LON2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S846233</td>\n",
       "      <td>vis/2019/SEVIR_VIS_STORMEVENTS_2019_0701_0731.h5</td>\n",
       "      <td>87</td>\n",
       "      <td>vis</td>\n",
       "      <td>2019-07-30 18:10:00</td>\n",
       "      <td>-121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>846233.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>25.233958</td>\n",
       "      <td>...</td>\n",
       "      <td>140775</td>\n",
       "      <td>846233</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>SE</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>26.6574</td>\n",
       "      <td>-80.2349</td>\n",
       "      <td>2639444</td>\n",
       "      <td>8014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S846233</td>\n",
       "      <td>ir107/2019/SEVIR_IR107_STORMEVENTS_2019_0701_1...</td>\n",
       "      <td>363</td>\n",
       "      <td>ir107</td>\n",
       "      <td>2019-07-30 18:10:00</td>\n",
       "      <td>-121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>846233.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>25.233958</td>\n",
       "      <td>...</td>\n",
       "      <td>140775</td>\n",
       "      <td>846233</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>SE</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>26.6574</td>\n",
       "      <td>-80.2349</td>\n",
       "      <td>2639444</td>\n",
       "      <td>8014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S846233</td>\n",
       "      <td>ir069/2019/SEVIR_IR069_STORMEVENTS_2019_0701_1...</td>\n",
       "      <td>363</td>\n",
       "      <td>ir069</td>\n",
       "      <td>2019-07-30 18:10:00</td>\n",
       "      <td>-121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>846233.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>25.233958</td>\n",
       "      <td>...</td>\n",
       "      <td>140775</td>\n",
       "      <td>846233</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>SE</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>26.6574</td>\n",
       "      <td>-80.2349</td>\n",
       "      <td>2639444</td>\n",
       "      <td>8014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S846233</td>\n",
       "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
       "      <td>275</td>\n",
       "      <td>vil</td>\n",
       "      <td>2019-07-30 18:10:00</td>\n",
       "      <td>-120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>846233.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>25.233958</td>\n",
       "      <td>...</td>\n",
       "      <td>140775</td>\n",
       "      <td>846233</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>SE</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>26.6574</td>\n",
       "      <td>-80.2349</td>\n",
       "      <td>2639444</td>\n",
       "      <td>8014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S846233</td>\n",
       "      <td>lght/2019/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5</td>\n",
       "      <td>0</td>\n",
       "      <td>lght</td>\n",
       "      <td>2019-07-30 18:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140775.0</td>\n",
       "      <td>846233.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>25.233958</td>\n",
       "      <td>...</td>\n",
       "      <td>140775</td>\n",
       "      <td>846233</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>SE</td>\n",
       "      <td>WELLINGTON</td>\n",
       "      <td>26.6574</td>\n",
       "      <td>-80.2349</td>\n",
       "      <td>2639444</td>\n",
       "      <td>8014094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          file_name  file_index  \\\n",
       "0  S846233   vis/2019/SEVIR_VIS_STORMEVENTS_2019_0701_0731.h5          87   \n",
       "1  S846233  ir107/2019/SEVIR_IR107_STORMEVENTS_2019_0701_1...         363   \n",
       "2  S846233  ir069/2019/SEVIR_IR069_STORMEVENTS_2019_0701_1...         363   \n",
       "3  S846233   vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5         275   \n",
       "4  S846233   lght/2019/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5           0   \n",
       "\n",
       "  img_type             time_utc  \\\n",
       "0      vis  2019-07-30 18:10:00   \n",
       "1    ir107  2019-07-30 18:10:00   \n",
       "2    ir069  2019-07-30 18:10:00   \n",
       "3      vil  2019-07-30 18:10:00   \n",
       "4     lght  2019-07-30 18:10:00   \n",
       "\n",
       "                                      minute_offsets  episode_id  event_id  \\\n",
       "0  -121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...    140775.0  846233.0   \n",
       "1  -121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...    140775.0  846233.0   \n",
       "2  -121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...    140775.0  846233.0   \n",
       "3  -120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...    140775.0  846233.0   \n",
       "4                                                NaN    140775.0  846233.0   \n",
       "\n",
       "  event_type  llcrnrlat  ...  EPISODE_ID_y  EVENT_ID  LOCATION_INDEX RANGE  \\\n",
       "0  Lightning  25.233958  ...        140775    846233               1  1.28   \n",
       "1  Lightning  25.233958  ...        140775    846233               1  1.28   \n",
       "2  Lightning  25.233958  ...        140775    846233               1  1.28   \n",
       "3  Lightning  25.233958  ...        140775    846233               1  1.28   \n",
       "4  Lightning  25.233958  ...        140775    846233               1  1.28   \n",
       "\n",
       "   AZIMUTH    LOCATION  LATITUDE  LONGITUDE     LAT2     LON2  \n",
       "0       SE  WELLINGTON   26.6574   -80.2349  2639444  8014094  \n",
       "1       SE  WELLINGTON   26.6574   -80.2349  2639444  8014094  \n",
       "2       SE  WELLINGTON   26.6574   -80.2349  2639444  8014094  \n",
       "3       SE  WELLINGTON   26.6574   -80.2349  2639444  8014094  \n",
       "4       SE  WELLINGTON   26.6574   -80.2349  2639444  8014094  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstset = pd.merge(df1, dfdetails, left_on='event_id', right_on='EVENT_ID')\n",
    "secondset = pd.merge(firstset, dffatalities, left_on='event_id', right_on='EVENT_ID')\n",
    "finalset = pd.merge(secondset, dflocations, left_on='event_id', right_on='EVENT_ID')\n",
    "\n",
    "finalset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5F.c\", line 509, in H5Fopen\n    unable to open file\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Fint.c\", line 1400, in H5F__open\n    unable to open file\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Fint.c\", line 1583, in H5F_open\n    file is already open for read-only\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-714f6b3aaf8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#store['table1Name'].to_csv('outputFileForTable1.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"can not be written\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Finally, create the File instance, and return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5F.c\", line 509, in H5Fopen\n    unable to open file\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Fint.c\", line 1400, in H5F__open\n    unable to open file\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Fint.c\", line 1583, in H5F_open\n    file is already open for read-only\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "#dataset = h5py.File(r'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5', 'r')\n",
    "from pandas import HDFStore\n",
    "\n",
    "store = HDFStore(r'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5')\n",
    "\n",
    "#store['table1Name'].to_csv('outputFileForTable1.csv')\n",
    "\n",
    "#read_file = pd.read_csv (r'Downloads/New folder/dset.asci')\n",
    "#read_file.to_csv (r'Downloads/New folder/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5/ does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-9d0a27baf59d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mstore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5/ does not exist"
     ]
    }
   ],
   "source": [
    "vis = pd.read_hdf(r'Downloads/New folder/SEVIR_LGHT_ALLEVENTS_2019_0701_0801.h5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Support for generic buffers has not been implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-0ca645907aba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mpath_or_buf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             raise NotImplementedError(\n\u001b[0m\u001b[0;32m    385\u001b[0m                 \u001b[1;34m\"Support for generic buffers has not been implemented.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Support for generic buffers has not been implemented."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "#s3 = boto3.client('s3')\n",
    "#obj = s3.get_object(Bucket='bucket', Key='key')\n",
    "bucket_name = 'sevir'\n",
    "\n",
    "# Your S3 Path goes here\n",
    "filename = 'data/vis/2019/SEVIR_VIS_RANDOMEVENTS_2019_0701_0710.h5'\n",
    "\n",
    "obj = s3.get_object(Bucket= bucket_name, Key= filename) \n",
    "\n",
    "df = pd.read_hdf(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
